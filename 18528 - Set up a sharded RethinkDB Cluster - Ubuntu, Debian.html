<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:mso="urn:schemas-microsoft-com:office:office" xmlns:msdt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882">

<head>

<title>Set up a sharded RethinkDB Cluster - Ubuntu, Debian</title>
<style type="text/css">
div.hacker {
background-color:#666;
border:1px solid #ccc;
color:#fff;
font-family:"Lucida Console","Courier New",Courier,fixed;  font-size:95%;  line-height:160%;  margin-bottom:1.5em;  padding:10px; }

p.note {
 background-color:#ffffe6;
 border:1px solid #eee;
 color:#666;
 padding:.8em 1.6em;
 margin:15px 0;
}

.warning {
 border: 1px #d25100 solid;
 padding: .5em 1em .5em 4em;
 margin: 10px 20px 15px 20px;
 background-image: url('@{help-img-path}/img_warning.gif');
 background-repeat: no-repeat;
 background-position: left top;
 background-color: #ededed;-moz-border-radius:
0.8em;-webkit-border-radius: 0.8em;
 /* -moz-border-bottom-radius: 0;9 */
 -webkit-border-bottom-radius: 0;
 padding-top:14px;
 padding-bottom:15px;
}
</style>


<!--[if gte mso 9]><xml>
<mso:CustomDocumentProperties>
<mso:ArticleKeywords msdt:dt="string">NoSQL, Scaling</mso:ArticleKeywords>
<mso:Reference msdt:dt="string">https://www.digitalocean.com/community/tutorials/how-to-create-a-sharded-rethinkdb-cluster-on-ubuntu-14-04, https://www.digitalocean.com/community/tutorials/how-to-create-a-sharded-rethinkdb-cluster-on-ubuntu-14-04</mso:Reference>
<mso:LinuxDistributions msdt:dt="string">;#Ubuntu;#Debian;#</mso:LinuxDistributions>
<mso:ArticlePriority msdt:dt="string">6</mso:ArticlePriority>
<mso:RequestNotes msdt:dt="string"></mso:RequestNotes>
<mso:Difficulty msdt:dt="string">3</mso:Difficulty>
<mso:ForkSplit msdt:dt="string"></mso:ForkSplit>
<mso:ArticleID msdt:dt="string">18528</mso:ArticleID>
<mso:UnsupportedFeatures msdt:dt="string"></mso:UnsupportedFeatures>
<mso:Collapsed msdt:dt="string"></mso:Collapsed>
<mso:Complexity msdt:dt="string"></mso:Complexity>
<mso:ArticleStatus msdt:dt="string">Not started</mso:ArticleStatus>


<mso:Sample msdt:dt="string">z</mso:Sample>
<mso:DeliveryTarget msdt:dt="string">Phase 1</mso:DeliveryTarget>
<mso:EditScore msdt:dt="string"></mso:EditScore>
<mso:PrereqOrdering msdt:dt="string">2</mso:PrereqOrdering>
<mso:AssignedTo1 msdt:dt="string">12</mso:AssignedTo1>
<mso:display_urn_x003a_schemas-microsoft-com_x003a_office_x003a_office_x0023_AssignedTo1 msdt:dt="string">Tom Taylor</mso:display_urn_x003a_schemas-microsoft-com_x003a_office_x003a_office_x0023_AssignedTo1>
<mso:Week msdt:dt="string">5.00000000000000</mso:Week>
</mso:CustomDocumentProperties>
</xml><![endif]-->
</head>

<body>
<p>Setting up a sharded RethinkDB cluster on Ubuntu and Debian, NoSQL</p>
    <h1>Set Up a Sharded RethinkDB Cluster - Ubuntu, Debian</h1>
    
    <p><strong>Difficulty</strong>: <em>3</em><br/>
        <strong>Time</strong>: <em>30 minutes</em></p>

    <p>RethinkDB, a NoSQL database, is the first open-source, scalable JSON database built from the ground up for  real-time web applications. It's designed specifically to push data to applications in real time, dramatically reducing the time and effort necessary to build scalable real-time applications. In this article, we'll help you build a RethinkDB cluster, import a database onto it, and make it secure.	</p>
<p>For these tasks, you'll need two servers running Ubuntu 14.04 or Debian 7, named <code>rethinkdb1</code> and <code>rethinkdb2</code><!--These are the two example names used in the Digital Ocean article. Please use something original. Also, please make sure that variables are properly formatted throughout this article. cj -->.  For optimal  security, set up a <code>sudo</code> user for each RethinkDB server.</p>
	

<h2>Set up a RethinkDB node</h2>
    
    <p>RethinkDB cluster is a type of peer-to-peer network. The primary step in building a RethinkDB cluster is to install RethinkDB on every server included in this cluster.</p>
	<ol>
	
	<li>On each server<!--Does the user perform all the steps on each server--or only step 1? cj -->, add the RethinkDB key and repository to <code>apt-get</code>.
<div class="hacker">source /etc/lsb-release &amp;&amp; echo "deb http://download.rethinkdb.com/apt </div>
		<div class="hacker">$DISTRIB_CODENAME main" | sudo tee /etc/apt/sources.list.d/rethinkdb.list</div>
		<div class="hacker">wget -qO- http://download.rethinkdb.com/apt/pubkey.gpg | sudo apt-key add –</div>
			</li>
	<li>Update and install RethinkDB.
		<div class="hacker">sudo apt-get update</div>
		<div class="hacker">sudo apt-get install rethinkdb</div>
		<p>RethinkDB is installed on the server. </p>
	</li>
	<li>Configure RethinkDB to run on startup.
		<div class="hacker">sudo cp /etc/rethinkdb/default.conf.sample</div>
		<div class="hacker">/etc/rethinkdb/instances.d/cluster_instance.conf</div>
		<div class="hacker">sudo vi /etc/rethinkdb/instances.d/cluster_instance.conf</div>
	</li>
	<li>Change the server name as follows:
	  <p>Search for:</p>
		<div class="hacker">server-name=server </div>
		<p>Change it to:</p>
		<div class="hacker">Server-name=rethinkdb1</div>
	</li>
	<li>Set up the bind address.  <br />
	  By default it<!--Please clarify what "it" pertains to. cj --> is accessible only on  localhost (127.0.0.1). Change this so that it listens on all network interfaces.
<p>Search for:</p>
		<div class="hacker">bind=127.0.0.1 </div>
		<p>Change it to:</p>
		<div class="hacker">Bind=all</div>
	</li>
	<li>Save the configuration changes.</li>
	<li>Start RethinkDB with a new build configuration.
      <div class="hacker">

sudo service rethinkdb start</div><div class="hacker">
sudo netstat -tulnp | grep rethindb</div>
The output looks like this:<br />
<div class="hacker"><pre>
tcp6       0      0 :::28016    :::*     LISTEN      2181/rethinkdb
tcp6       0      0 :::8080     :::*     LISTEN      2181/rethinkdb
tcp6       0      0 :::29015    :::*     LISTEN      2181/rethinkdb
</pre>
  </div>
	  </li>	
	</ol>

  
<h2>Secure the RethinkDB cluster</h2>
	<p>You've now configured RethinkDB to  listen on all network interfaces (<code>bind=all</code>). However, this  exposes RethinkDB  to outside networks and presents a security threat. In this section we'll make RethinkDB accessible only from authorized computers.</p>
	<p>In the above  <code>netstat</code> command results, you  see three different ports on which RethinkDB listens:</p>
	<ul>
	  <li> Port 8080 is used for the RethinkDB web management console.</li>
	  <li>Port  28015 is the driver port. </li>
	  <li>Port 29015 is the cluster port.</li>
</ul>
<p>We'll secure the cluster port through the firewall, and we'll use SSH tunnels to securely access the web management console and the driver port.</p>
	<ol>
	<li>Block all outside connections. Perform the following steps on all <!--Aren't there only two RethinkDB servers in our example? Also, does the user perform all steps on all servers--or only this step 1? Unclear. cj -->RethinkDB servers. 
	  <p>Web Management Console:</p>
	<div class="hacker">sudo iptables -A INPUT -i eth0 -p tcp --dport 8080 -j DROP</div>
	<div class="hacker">sudo iptables -I INPUT -i eth0 -s 127.0.0.1 -p tcp --dport 8080 -j ACCEPT</div>
	
	<p>Driver Port:</p>
	<div class="hacker">sudo iptables -A INPUT -i eth0 -p tcp --dport 28015 -j DROP</div>
	<div class="hacker">sudo iptables -I INPUT -i eth0 -s 127.0.0.1 -p tcp --dport 28015 -j ACCEPT</div>
	
	<p>Cluster Port:</p>
	<div class="hacker">sudo iptables -A INPUT -i eth0 -p tcp --dport 29015 -j DROP</div>
	<div class="hacker">sudo iptables -I INPUT -i eth0 -s 127.0.0.1 -p tcp --dport 29015 -j ACCEPT</div>
	</li>
	
	<li>Install <code>iptables-persistent</code> to save the rules.
<div class="hacker">sudo apt-get install iptables-persistent</div>
      
      <!--Is the following div supposed to be replaced with an image? Also, be aware that images should not be screen output. cj -->
	<div class="hacker">&lt;Screnshot: 18528-iptables_save&gt;</div>
	<li>At the  prompt, select <strong>(yes)</strong> to save ipv4 and ipv6 rules.</li>
	</li>
	</ol>
	
	<h2>Set up a management user</h2>
	<p>Next we need to set up SSH tunnels to access RethinkDB's web management console and the driver interface securely.</p>
	<ol>
	  <li> Create a management user for SSH tunnel in <code>rethinkdb1 </code>
	    <div class="hacker">sudo adduser sshuser</div>
	</li>
	
	<li>Set up the authorized keys file for a new user.
	<div class="hacker">sudo mkdir /home/sshuser/.ssh</div>
	<div class="hacker">sudo touch /home/sshuser/.ssh/authorized_keys</div>
	</li>
	
	<li>Import the public key from a local computer, from where you'll access the RethinkDB web management console. You can either copy the public key directly from your computer, or you can use <code>ssh-copy-id</code> command.
	</li>
	<li>Copy the user public key.</li>
	<li>Open  <code>authorized_keys</code> for editing.
	  <div class="hacker">sudo vi /home/sshuser/.ssh/authorized_keys</div>
	  </li>
	<li>Paste the user public key into this file. </li>
	<li>Repeat the above steps to create other cluster nodes.</li>
	</ol>
	
<h2>Import or create a database</h2>
	<p>If you already have a database on this  or another server,  you need to import those databases into your cluster. If there is no database,  RethinkDB  creates an empty database by default<!--If they don't have a database, do they skip this section? cj -->.</p>
	<ol>
	  <li> Copy the database that you want to import on <code>rethinkdb1</code>, if not already present. First you need to find the path of your current RethinkDB database. (If you used the <code>rethinkdb</code> command to start your old database, then the directory path<code> is rethinkdb_data.)</code> Use the <code>scp </code>command to copy it to <code> rethinkdb1 </code><!--This step is confusing as written. The user is told to do three different things. Also, what if they don't have a database (a possibility mentioned in the intro)? cj -->
	    <div class="hacker">sudo scp -rpC From Server User@From Server IP:/RethinkDB Data Folder/* </div>
	<div class="hacker">/var/lib/rethinkdb/cluster_instance/data</div>
		
	</li>
	
	<li>Restart RethinkDB. 
	  <div class="hacker">sudo service rethinkdb restart</div>
	</li>
	
	<li>If you have an existing RethinkDB database on <code>rethinkdb1</code>, open the configuration file on <code>rethinkdb1 </code>
	  <div class="hacker">sudo vi /etc/rethinkdb/instances.d/cluster_instance.conf</div>
	</li>
	
	<li>Find the path of the RethinkDB database to import. If you used the <code>rethinkdb</code> command to start your old database, the directory is <code>rethinkdb_data</code>. Insert that path into the configuration file.
	  <div class="hacker">directory=/home/user/rethink/rethinkdb_data/</div>
	</li>
	
	<li>Save the changes. </li>
	<li>Restart RethinkDB.
      <div class="hacker">sudo service rethinkdb restart</div>
	  </li>
</ol>

<h2>Create a cluster</h2>
	<ol>
	<li>To create a cluster, first allow all cluster machines to be accessed through each other’s firewall. Now on <code>rethinkdb1</code> server, we will allow all other servers to connect to cluster port through firewall.
<div class="hacker">sudo iptables -I INPUT -i eth0 -s other_server_ip_address -p tcp --dport 29015 -j ACCEPT</div>
	</li>
	
	<li>Repeat the same command for any other nodes you want to add.  Replace <code> other_server_ip_address </code><!--Is this a variable? If so, please format it correctly. cj -->with respective server IP addresses. </li>
	<li>Save the firewall changes.
	  <div class="hacker">sudo sh -c "iptables-save > /etc/iptables/rules.v4"</div>
	</li>
	<li>Repeat these steps for your other servers. <br />
	  Once ports are opened and servers can communicate to one another, you can connect other servers to create a cluster. </li>
	<li>To connect other servers,  access the <code>rethinkdb2</code> server, and edit the following configuration file:
	  <div class="hacker">sudo vi /etc/rethinkdb/instances.d/cluster_instance.conf</div>
	  </li>
	<li>Join this server (<strong>rethinkdb2</strong>) to the cluster: Find the <code>join</code> statement in the file.
	  <div class="hacker">join=example.com:29015</div>
	<p>Replace it with the following:</p>
	<div class="hacker">join=rethinkdb1_IP</div>
	</li>
	
	<li>Save the configuration file, and then restart RethinkDB.
	  <div class="hacker">sudo service rethinkdb restart</div>
	</li>
	
	<li>Perform the same steps for other servers.  <br />
	  In the first node, <strong>rethindb1</strong> does not need a <code>join</code> statement as we are joining other servers to rethinkdb1.
	<br />
	After completing this step, you  have all servers joined to <strong>rethinkdb1</strong> and  have a fully functioning RethinkDB cluster.
	<img src="images/18528 - 1.png" alt="18528 - 1.png"/>
	</li>
	</ol>
	
<h2>Connect to the web management console</h2>
	<p>You can use the RethinkDB web management console for an online platform to perform basic functions on RethinkDB such as creating databases and tables, changing basic table settings, and running RethinkDB commands. </p>
	<ul>
	<li>Enable security on the web management console by using SSH tunnel to connect to  the web management console. 
	  <div class="hacker">ssh -L 8080:localhost:8080 sshuser@rethinkdb1_IP</div>
	Since you have already completed the SSH key transfer, you can directly execute the above command. If you receive an error (such as &quot;address already in use&quot;), then change the port number and connect to <code>rethinkdb1</code> with the same command
	<div class="hacker">Eg: ssh -L 8081:localhost:8080 sshuser@rethinkdb1_IP</div>
	</li>
</ul>
	
	<h2>Connect to the cluster using Python driver</h2>
	In this section we'll use a SSH tunnel to establish a connection with the driver port. Because we already have secured the connection to the cluster nodes, no one from outside the network can access the cluster port.
	<p>Now we'll create a SSH tunnel from one of the servers (<code>rethinkdb2</code>), so that they can establish a secure connection to the cluster port (29018).</p>
	<ol>
	
	<li>Perform following steps in <code>rethinkdb2</code> to generate a SSH key.	
	  <div class="hacker">ssh-keygen -t rsa</div>
	</li>
	
	
	<li>Copy the public key (<code>id_rsa.pub</code>) to rethinkdb1 server (Cluster Node), and add in <code>authorized_keys</code>.
<div class="hacker">sudo vi  /home/sshuser/.ssh/authorized_keys
	</div>
	</li>

	<li>Use SSH tunneling to access the driver port from the sever.
	  <div class="hacker">ssh -L 28015:localhost:28015 sshuser@cluster_node_ip -f -N</div>
	If you get a &quot;bind: Address already in use error,&quot; you can change the port. 
	<div class="hacker">Eg: ssh -L 28016:localhost:28015 sshuser@cluster_node_ip -f –N</div>
	</li>
	</ol>
	
	<h2>Install the Python driver</h2>	<!--This section seems to be about more than installing a driver. Is this header incomplete? cj -->
<ol>
	<li>To install the Python driver on the connecting server (<code>rethinkdb2</code>), install the Python virtual environment. 
	  <div class="hacker">sudo apt-get install python-virtualenv</div>
	</li>
	
	<li>Create a directory named <code>rethink</code> in user home directory.
<div class="hacker">mkdir rethink</div>
	<div class="hacker">cd rethink</div>
	</li>
	
	<li>Create the new virtual environment structure.
	  <div class="hacker">virtualenv venv</div>
	</li>
	
	<li>Activate the environment before starting Python.
	  <div class="hacker">source venv/bin/activate</div>
	</li>
	
	<li>Install the RethinkDB module.
	<div class="hacker">pip install rethinkdb</div>

	</li>
	
	<li>Start Python from the connecting server.
	<div class="hacker">Python</div>
	</li>
	
	<li>Connect to the cluster server database.  Make sure to provide the correct port, which you  used earlier to connect to the SSH tunnel.
	  <div class="hacker">import rethinkdb as r</div>
	<div class="hacker">r.connect("localhost", 28016).repl()</div>
	</li>
	
	<li>Create a table test.<!--This table test is copied from the Digital Ocean article. Please use something original. cj -->
	<div class="hacker">r.db("test").table_create("test").run()</div>
	</li>
	
	<li>Insert data into the table test.
	<div class="hacker">r.db("test").table("test").insert({"hello":"world"}).run()</div>
	<div class="hacker">r.db("test").table("test").insert({"This”:”Is”:”world”}).run()</div>
	</li>
	
	</ol>
	
	<h2>Sharding</h2>
	
	<p>RethinkDB allows you to shard and replicate your cluster on a per-table basis.  You can control the sharding settings through web management console.</p>
	<p>When using the web management console, you can perform sharding  simply by specify the number of shards you want and based on the data available, RethinkDB will determine the best split points to maintain balanced shards. To shard your data:</p>
	<ul>
	<li>Go to the table view (Tables &rarr; table name).</li>
	<li>Click on the Reconfigure button.</li>
	<li>Set the number of shards and replicas you want.</li>
	<li>Click on the Apply Configuration button.</li>
	</ul>
	<p>In addition to the options in web management console,<code> ReQL </code>commands for table configuration allow both scripting capability and replication, distributing replicas for individual tables across user-defined groups of servers using server tags. All these functionalities can be achieved through <code>ReQL</code> command.</p>
	<p>There are three primary commands for changing sharding and replication in ReQL:</p>
	<ul>
	<li><code>table_create</code> : Specify initial values of shards and replicas.
	</li>
	<li><code>reconfigure</code> : Change the values of shards and replicas.
	</li>
	<li><code>rebalance</code> : Used to rebalance table shards.
	</li>
		</ul>
	
		<img src="images/18528 - 2.png" alt="18528 - 2.png"/>
	
	<h2>Advanced configuration</h2>
	<p>These include advanced configuration which cannot be performed through the web interface.</p><!--Are the next three sections part of the advanced configuration? If so, they should use h3 headers, not h2. If not, this one-sentence section is not so helpful. Is something missing? cj -->
	
	<h2>Server tag</h2>
	<ol><!--Please make sure that the first sentence in each step has an imperative statement ("do such and such"). cj -->
	<li>All servers in a RethinkDB cluster may be given zero or more tags that can be used in table configurations. This is used to map replicas to servers specified by tags. We can set a tag through the below command:
	<div class="hacker">rethinkdb --server-tag us --server-tag us_west</div>
	</li>
	<li>If no tags are specified on startup, the server will be started with default tag (default). When servers are tagged, you can use the tags in the reconfigure command:<!--The command appears to be missing. cj --></li>
	<li>If we want to assign three replicas of the user's table to <code>us_1</code> and two to <code>us_2</code>, use the following command:
<div class="hacker">r.table('users').reconfigure(shards=2, replicas={'us_1':3, 
    'us_2':2}, primary_replica_tag='us_2').run(conn)
</div>
	</li>
	</ol>
	<h2>Write acknowledgements and durability</h2>
	<p>Write acknowledgements and write durability are two other settings that can't be configured or managed through the web management console or  <code>reconfigure</code> command.  They can  be configured only by editing table <code>table_config</code> for each individual table.</p>
<p>The write acknowledgement setting for a table controls when the cluster acknowledges a <code>write</code> request as completed. There are two possible settings:</p>
	<ul>
	<li><code>majority:</code> The cluster sends the acknowledgement when the majority of replicas have acknowledged it. This is the default.
	</li>
	
	<li><code>single:</code> The cluster sends the acknowledgement when any replica has acknowledged it.
	</li>
</ul>
	<p>Below is an example:</p>
	
	<div class="hacker">
r.db('rethinkdb').table('table_config').get(
    '31c92680-f70c-4a4b-a49e-b238eb12c023').update(
        {"write_acks": "single"}).run(conn)

</div>
	
	<p>The durability setting for a table controls when writes are committed. They include both hard and soft mode:</p>
	<ul>
	<li>In hard mode, writes are committed to disk before acknowledgements are sent
	</li>
	<li>In soft mode, writes are acknowledged immediately upon receipt. This is much faster.
	</li>
	</ul>
			
	<h2>Remove a server</h2>
	<p>Removing a server from the cluster must be performed carefully. When a document is divided over multiple servers, one server  always keeps its primary index.  If the server holding the primary index of the document is taken offline, then the document is lost. Therefore, before removing a server, you need to migrate all its primary shards away from it. </p>
	<p>Here we'll migrate data off  the node <code>rethinkdb2</code> to make <code>rethinkdb1</code>  the sole node. Then we can remove the <code>rethindb2</code> node safely.</p>
		<ol>
	<li>Enter  the RethinkDB admin shell on <code>rethinkdb1.</code>
	  <div class="hacker">rethinkdb admin</div>
	</li>
	
	<li>List the shards (groups of documents) that <code>rethinkdb2</code> holds.
	<div class="hacker">ls rethinkdb2</div>
	</li>
	
	<li>Move the shards from one server (<code>rethinkdb2</code>) to another (<code>rethinkdb1</code>).
	  <div class="hacker">pin shard TABLE SHARD-RANGE --master MACHINE-NAME</div>
	<div class="hacker">Eg : pin shard food.foodshards -inf-+inf --master rethinkdb1</div>
		</li>
	
	<li>Exit from the admin shell.
	  <div class="hacker">Exit</div>
	Now you can safely stop RethinkDB on the server (<code>rethinkdb2</code>). </li>
	<li>Execute this command in <code>rethinkdb2</code>:
<div class="hacker">sudo service rethinkdb stop</div>
	  </li>
    </ol>
<p>After you remove this server (<code>rethinkdb2</code>),  you receive a warning message when accessing the RethinkDB web management console.  On the right-hand side of the  message is a permanent remove button. You can click this button to remove this server (<code>rethinkdb2</code>) from the cluster. <!--Is this part of the procedure? If so, it should be a numbered step. --></p>
<h2>Conclusion</h2>
    <p>In this article, we discussed the steps involved in setting up a sharded RethinkDB cluster on Ubuntu and Debian servers.</p>
</body>
</html>